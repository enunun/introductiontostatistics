#import "../layout/layout.typ": *
#import "@preview/in-dexter:0.7.2": *
#show: great-theorems-init

= p値と仮説検定 <chap:testing>

第1章では，初等教育における確率概念の問題点とその解決策としての公理的確率論を紹介した．
はっきりいって，統計学を応用するうえでは公理的確率論を知らないと進まない議論というのはほとんど存在しない．ではなぜあんなにもページ数を割いて紹介したかといえば，読者に現実世界と数理モデルとを明確に区別する体験をしてもらいたかったからである．

仮説検定は，現実世界で取得されたデータと数理モデルとを比較する営みであると考えることができる．
ともすれば，仮説検定をすでに学んだことのある読者の頭には大量のはてなマークが浮かんでいるかもしれない．
すでに学んだ「仮説検定」の姿とあまりにも違いすぎるからである．
仮説検定は「現実世界で取得されたデータと数理モデルとを比較する営み」と考えるのがもっとも的確で，かつスッキリと理解しやすい言語化である．

伝統的な統計学の教科書では（公理的確率論を積極的に扱う本であっても！）数理モデルの存在が前面に押し出されることはあまりない．
よく読めばわかるようになっていることも多いが，
わかりやすく解説してくれることはほとんどない．

本章では，その仮説検定を現実世界で取得されたデータと数理モデルとを比較する営みという観点から紹介する．

== 大数の法則

まず第一に，現実世界での統計的確率と数理モデル内での確率をつなぐ道具として活用できる大数の法則を紹介する．

#theorem(title: "大数の強法則")[
  確率空間$(Omega, scr(B), P)$上の確率変数列
  $
    X_1, X_2, dots, X_n, dots
  $
  が以下の条件を満たすとする：

  1. 独立である
  2. 同分布である．すなわち，各$X_i$がすべて同じ分布に従う．
  3. 各$X_i$の期待値がすべて有限確定である．

  各$X_i$はすべて同じ分布に従うので，その期待値が有限確定であればすべて同じ値である．それを$mu$とする．
  各自然数$n$に対し，
  $
    dash(X)_n = 1 / n sum_(i = 1)^n X_i
  $ <eq:sample-mean>
  と定める．
  この$dash(X)_n$は確率空間$(Omega, scr(B), P)$上の確率変数となる．
  このとき，以下が成り立つ：
  $
    P(lim_(n arrow.r infinity) dash(X)_n = mu) = 1
  $
] <thm:raw>

#example[
  二項分布$bin(1, 1 / 2)$を考える．
  二項分布に従う確率変数$X$を考えると，その期待値は @ex:bin-expectation で述べたように$1 / 2$である．
  試行回数を表すパラメータは$n = 1$なので，
  $X$の実現値は0か1かのいずれかである．
  そして，(2.2) 式はこの1回の試行そのものを$n$回繰り返したときにでた1の回数の平均値を表す．
  @thm:raw は，繰り返し回数$n$を限りなく大きくするとその平均値が期待値の$1 / 2$に限りなく近づく確率が1になるという主張である．

  これはちょうど @ex-coin-toss-ratio で観察した結果と符合する．大数の（強）法則自体は数理モデル内で完結した定理なので現実世界には機械的に適用できないとはいえ，数理モデル内で定義した期待値と現実世界で取得した平均値とが一致するということを*示唆する*定理である．
]

#pagebreak()

== p値と信頼区間

ここでは二項分を例にして，現実世界で取得したデータとモデルとを比較する指標となる$p$値と信頼区間について述べる．

二項分布$bin(n, p)$はパラメータを2つもつ分布である．
ここでは，そのうち試行回数を表すパラメータ$n$を20で固定する．

20回コインを投げてそのうち表が14回出たとしよう．
このとき，現実世界において表が出た回数14回が二項分布$bin(20, p)$に従う確率変数の実現値として得られる確率空間における確率を計算することができる．

$p$値の計算では，現実世界において取得した結果よりも「極端な」結果が得られる確率を考える．
何をもって極端とするかはいろいろ議論があるのだが，ここでは「実現値として得られる確率が実現値14が得られる確率よりも低いもの」を極端であると考えよう．
つまり，以下のいずれかが成り立つ確率を求めるということである．

- 実現値が14より大きい．
- 実現値が6より小さい．

この値は，もう一つのパラメータ$p$の関数として計算することができる．
#index(display: "p値関数")[p値関数]
#index(display: "p値")[p値]
このように，現実世界で得られたデータよりも極端な結果が数理モデル内で得られる確率を*$p$値*といい，それをパラメータの関数としてとらえたものを*$p$値関数*という．

今回の試行における結果をパラメータ$p$の関数としてプロットしたのが以下の @p-value-function である．

#figure(
  image("fig/p-value-function.svg"),
  caption: "二項分布におけるp値関数のグラフ，試行回数20回で14回対象の事象が発生したものと想定したグラフである．",
) <p-value-function>

$p$値関数の値がもっとも大きくなるのは$p = 14 / 20 = 0.7$の場合である．このとき，確率変数の期待値が結果として得られた対象の事象が発生した回数の平均値と完全に一致する．$p = 0.7$の場合の確率空間がこのデータともっとも「相性がいい」ということとなる．

値が小さくなる方に目を向けよう．パラメータ$p$が0.4を下回ったあたりと$0.8$を上回ったあたりから$p$値が急速に小さくなっている．この場合，$p$がそれほどまでに大きい，あるいは小さい場合の確率空間で「20回中14回事象発生」という現象は極めて発生しづらい，ということとなる．

#index(display: "信頼区間")[しんらいくかん]
@p-value-function には横線が引いてある．この横線は$p$値が0.05になる値に合わせて引かれている．$p$値がこの値を下回らないパラメータの値の集合を*信頼区間*と呼ぶ．

== 仮説検定

#index(display: "仮説検定")[かせつけんてい]
前述した$p$値を使い，現実世界で取得したデータとモデルとを比較して何かしたらの判断を下すことがある．
例えば @p-value-function の結果においては，パラメータ$p$が0.2であるようなモデルとデータとの相性は極めて悪い．
すなわち「今回のデータと同じデータがモデル内で得られる確率は極めて低いので，今回のデータを発生させた現象や集団は，今回採用したモデルに従っていないと考えることとする」といった具合に判断を下すことがあるのである．

ともすれば，仮説検定を履修済みの読者は「もっと強い結論が得られているはずだ」と考えるかもしれない．
しかし，統計学の範疇で言えるのは実はここまでである．
ここからさらに結論を強めたい場合，その責任は結論を出したい当事者が負わなければならない．統計学に限らず，ありとあらゆる知見を総動員して議論を行うべきである．
