#import "../layout/layout.typ": *
#import "@preview/in-dexter:0.7.2": *
#show: great-theorems-init

= 確率論 <chap:probability>

統計学は偶然を伴う現象を定量的に取り扱う．そのため，その基礎となるのは確率論である．
我が国では，確率論は初等教育でも学ぶが，当然のことながらいわゆる公理的確率論には触れず，
現実世界と密接に結びついたもののみ取り扱っている．高等教育まで含めても，そもそも公理的確率論を学ぶ人自体多いわけではない．
やはりそれは公理的確率論が数学の教科書に載っている言葉遣いを積極的に使っていることが大きいのだろう．

一方で，数理モデルとの関係を前面に出して統計学を学ぶという本書のコンセプト上，公理的確率論は絶対に避けられない．
確率論において「数理モデル」に相当する理論は公理的確率論だからである．

まずは初等教育で取り扱う統計的確率と数学的確率について簡単に復習し，その「定義」のどこにあいまいさがあるのかを述べる．
その後，その問題を解消する手段として公理的確率を導入し，そこで定義された「確率」と上記「確率」との関係について述べる．
最後に確率変数や確率分布を定義し，統計学の基礎としての最小限の概念を導入する．
扱っている内容自体は通常の統計学の教科書とほとんど変わらない．数学的な深堀はそちらの教科書を参照せよ．

== 古典的確率論 <sec:classical-probability>

数理モデルとしての公理的確率論を導入する前に，まずは初等教育で学ぶ確率論について復習しよう．

#index(display: "試行")[しこう]
#index(display: "事象")[ししょう]
#definition[
  まったく同じ条件で繰り返し行うことができる動作を*試行*と呼ぶ．そして，試行の結果生じた現象を*事象*と呼ぶ．
]

#example[
  「表裏のあるコインを1回投げる」という動作は同じ条件で繰り返し行うことができる．よってこの動作は施行である．また，その結果である「表が出る」「裏が出る」という現象は事象である．
]

このような試行や事象について，細かい違いはあれど中学校では大別して2種類の確率が導入される．

#index(display: "統計的確率")[とうけいてきかくりつ]
#definition(title: "統計的確率")[
  ある試行を$n$回繰り返したとき，着目した事象が$m$回起こったとする．
  このとき，$n$を大きくするにつれて比
  $
    m/n
  $
  が一定の値に限りなく近づくならば，
  その一定の値をその事象が起こる*統計的確率*と呼ぶ．
]

#example[
  あるコインを何回も投げた場合に表が出る回数がなるかを調べてみよう．
  @coin-toss-ratio は，この実験を仮想的にシミュレーション上で行った結果を表している．
  結果を見ると，試行回数が増えるにつれて試行回数に対する表が出た回数の比率がなんとなく一定値に近づいていくように見える．

] <ex-coin-toss-ratio>

#figure(
  image("fig/coin_toss_ratio.svg"),
  caption: "コイン投げの回数と表が出る比率の関係，コインを10, 30, 100, 300, 1000, 3000, 10000回投げた場合に表が出た回数を試行回数で割った比率をプロットしたものである．",
) <coin-toss-ratio>

#v(1em)

さて，このシミュレーション結果を見て，このコインを投げたときに表が出る統計的確率は$0.5$であると結論づけてよいだろうか？
答えはもちろん否である．
実際に実験していないシミュレーションだろう，という突っ込みを置いておいたとしても，
例えば以下の問いに対する答えは現時点では何も与えられていない．

1. 表が出る回数の比率は本当に一定値に近づくのだろうか？例えば投げる回数が$10^9$あたりになったときに突然比率が$0.3$あたりに近づくことはないだろうか？
2. 仮に一定値に近づくとして，その一定値は本当に$0.5$なのだろうか？$0.5000000000000001$ではないことはどうやって保証できるだろうか？

要するに，統計的確率は「定義」には見えるけども，実際には「定義」と呼べるほどしっかりしたものではないということである．「コインを1回投げたときに表が出る統計的確率」すらこの「定義」からは導出できないのである．

#remark[
  さて，上記の議論に対して「極論である」という印象を持った読者も多いであろう．
  その源泉にあるのはおそらく「0.5であるという素朴的直観」である．
  あるいはもう少し進んで「大数の法則というのがあって...」と考えたかもしれない．
  しかしのちに述べるように，数学的に厳密に証明できる定理という意味での「大数の法則」は，
  公理的確率論における定理である．すなわち，この「大数の法則」は，現実世界の試行に基づく「統計的確率」を正当化してはくれないのである．
] <intuition-probability>

@intuition-probability で述べたように，我々は「コインを1回投げたときに表が出る統計的確率は0.5であろう」という素朴的直観を持っている．
この素朴的直観をもたらすのは，おおよそ以下の数学的確率である．

#index(display: "数学的確率")[すうがくてきかくりつ]
#index(display: "同様に確からしい")[どうようにかくらしい]
#definition(title: "数学的確率")[
  ある試行において，起こりうるすべての事象が全部で$n$通りあり，それらの起こりやすさはすべて等しいものとする．
  このことを，これらの事象はすべて*同様に確からしい*という．
  このとき，そのうちのある事象が起こる場合は全部で$m$通りあるならば，比
  $
    m/n
  $
  をその事象が起こる*数学的確率*と呼ぶ．
] <mathematical-probability-def>

#example[
  「コインを1回投げる」という施行を考える．
  このとき，起こりうる事象は「表が出る事象」と「裏が出る事象」の2通りがあり，この2通りの事象は同様に確からしい．
  よって，このときの「表が出る」という事象の数学的確率は$1/2 = 0.5$である．
]

一見この定義は，あいまいさのないきちんとした定義に見える．しかし残念ながら，この「定義」にもあいまいさが残っている．このあいまいさを理解しやすい例を挙げよう．

#example[
  「コインを2回投げる」という試行を考える．「表が1回だけ出る」事象の数学的確率を考えよう．
  まず，起こりうる事象をすべて列挙すると以下の3通りがある．
  - 表2回
  - 表1回，裏1回
  - 裏2回
  従って，「表が1回だけ出る」という事象の数学的確率は$1/3$である．

  一方で，起こりうる事象を以下の4通りに分けてみよう．
  - 両方表
  - 1枚目が表，2枚目が裏
  - 1枚目が裏，2枚目が表
  - 両方裏
  このように分けてみると，「表が1回だけ出る」事象は2通りあるからその数学的確率は$2/4 = 1/2$である．
] <example-mathematical-probability>

さて， @example-mathematical-probability で述べた2つの解答のうちどちらが「正しい」解答であろうか？
中学校で確率を学んだ読者であれば，おそらく「後者である」と答えるであろう．
その理由は何かと問われれば，「前者は列挙された事象が同様に確からしくなく，後者は列挙された事象が同様に確からしいからだ」と答えるであろう．
ところが，その解答に対してさらに「同様に確からしいのはなぜか？」と問われれば解答に窮するのではないだろうか？
「たぶんそうだろう」とまではいえても一切のあいまいさが排除された完璧な解答を与えることはほとんど不可能であるように思われる．

答えに窮する根本原因は「同様に確からしい」という術語の定義があいまいであることにある．
事象の起こりやすさがすべて等しいというのはどういうことであろうか．「事象の起こりやすさ」という概念自体よくわからないものである．
思いつくものとしては「同様に確からしい」というのを「その統計的確率がすべて等しい」と言い換えるという案が考えられる．
この案の背景にあるのは「統計的確率と数学的確率は一致すべき」という思想であり，それなりに妥当であるように思われる．
しかし先に述べたように，統計的確率自体あいまいさなく定義されているようなものではないから，この言いかえは根本原因の解決策とはなりえない．

#remark[
  数学的確率は現実世界における実験を伴わない確率概念であり，しばしば数理モデルにおける概念として扱われることも多い．しかし，それは単に実験していないだけであってその考えは明らかに現実世界における素朴的直観に立脚している．そこで本書では，この「数学的確率」を数理モデルにおける概念とはみなさない．
]

== Bertrandのパラドックス

@sec:classical-probability で述べたように，統計的確率も数学的確率も，素朴的直観に頼ったあいまいな定義であった．
このあいまいさに対する解決策の前に，このあいまいさを引き立たせる有名なパラドックスを紹介しよう．

#index(display: "Bertrandのパラドックス")[Bertrandのパラドックス]
#example(title: "Bertrandのパラドックス")[
  正三角形と，その三角形の内接円を考える．
  円の弦をランダムに1本引くとき，その弦の長さが正三角形の一辺の長さよりも長くなる確率を求めよ．
] <bertrand-paradox>

この問題に対しては，以下のように複数の解答が考えられる．
問題を解く前に，数学的確率を以下のように拡張しておこう．

#definition[
  長さ$L$の曲線$C$が与えられたとし，$C$の部分集合$C'$の長さが$l$であるとする．
  $C$上から1点を選ぶという試行を考えるとき，その選び方がすべて同様に確からしいのであれば，この試行において$C'$上の点が選ばれるという事象の数学的確率を
  $
    l / L
  $
  と定める．
] <continus-probability>


@continus-probability に基づき，@bertrand-paradox に対する解答を2通り挙げよう．

#answer[
  弦を1本引くことは，円周上の2点を選ぶことと等価である．
  そして，選ばれた2点のうち一方が正三角形の1頂点と一致させるように回転させる．
  このとき，選ばれた2点を結ぶ弦が正三角形の一辺よりも長くなるための条件は，もう一方の点が正三角形の残りの2頂点を結ぶ孤（ @bertrand-figure1 でいえば孤BC）上にあることである．
  その孤の長さは円周全体の$1 / 3$である．

  つまりこの問題は，円周全体からランダムに点を1つ選ぶとき，その点が円周全体の$1 / 3$の領域に入る確率を求めることであると考えられる．
  ゆえにそのような確率も$1 / 3$である．
] <bertrand-paradox-answer1>

#figure(
  image("fig/Bertrand_1.svg", width: 7cm),
  caption: "Bertrandのパラドックスにおける弦の引き方の例1，図で実線の弦は正三角形の一辺よりも長いが，破線の弦は正三角形の一辺よりも短い．",
) <bertrand-figure1>

#answer[
  まず，円の半径とその上の点を無作為に1本選択する．
  そして，選ばれた点を通りその半径に垂直な弦を考える．
  半径とその上の点のペアは，円の弦全体とちょうど1対1に対応する．
  従って，円の弦をランダムに選択することは，円の半径とその上の点をランダムに選択することと等価である．

  さて，選ばれた円の半径とその上の点に対し，対応する弦が正三角形の一辺と垂直になるよう正三角形を回転させる．
  このとき，対応する弦が正三角形の一辺よりも長くなる条件は，弦と垂直になった辺と半径との交点よりも選ばれた点が円の中心に近いことである．この交点は半径の中点なので，そのような確率は円の半径から点をランダムに選ぶときに半分の部分から点が選ばれる確率に等しい．そのような確率は$1 / 2$である．
] <bertrand-paradox-answer2>

#figure(
  image("fig/Bertrand_2.svg", width: 7cm),
  caption: "Bertrandのパラドックスにおける弦の引き方の例2，図で実線の弦は正三角形の一辺よりも長いが，破線の弦は正三角形の一辺よりも短い．",
) <bertrand-figure2>

ここでは解答を2通り取り上げたが，どちらの解答も本質的には円の弦全体の集合への別の集合への全単射を適当に作り，その集合上の元の選び方に対する確率を考えているだけである．
最終的な解答も，その集合の作り方次第でいくらでも変えられる．

無限集合が介在する問題であるため，これほどまでに解答にバリエーションが考えられたが，その本質にあるのはやはり「同様に確からしい」という用語に対するあいまいさである．

@bertrand-paradox-answer1 では，本質的には円周上から1点を選ぶという試行においてその点の選び方すべてを同様に確からしいと考え，
そのうち円周の$1 / 3$の長さの部分の点が選ばれる確率を考えた．
そして @bertrand-paradox-answer2 では，本質的には線分上から1点を選ぶという試行においてその1点の選び方すべてを同様に確からしいと考え，
そのうち半分の長さの部分の点が選ばれる確率を考えた．

以上のことからわかるように，何が「同様に確からしい」かはアプリオリに決まっているというよりは自分で決めるという方が近い．
であれば，もはや「同様に確からしい」という術語を基礎に置く必要もないだろう．
そういうわけで，現代では「同様に確からしい」のような「ランダム性」を基礎におかない議論の進め方が主流である．

#remark[
  読者の中には「どれが正しいかは実験して確かめればいい」と考えたかもしれない．
  残念ながら，現実世界の実験ではやはり「たぶんそうだろう」ということしかわからない．
  しかし発想自体は悪くない．
  この考え方を洗練させ，定量的な議論を行うのが仮説検定である．
]

== 公理的確率論 <sec:axiomatic-probability>

古典的確率論では現実世界における「ランダム性」を基礎にしてしまったせいで議論にあいまいさが残ってしまう事例を見た．
ここでは，現実世界とは完全に切り離して議論を進めることによりそのあいまいさを排除することを試みる．
ここから一気に数学色が強くなってくる．

#index(display: "可測空間")[かそくくうかん]
#index(display: "可測集合")[かそくしゅうごう]
#definition(title: "可測空間")[
  集合$Omega$が与えられたとする．
  このとき，$Omega$の部分集合からなる集合$scr(B)$が以下の条件をすべて満たす場合，
  $scr(B)$を$Omega$上の$sigma$加法族と呼ぶ．

  1. $emptyset in scr(B)$である．
  2. $B in scr(B)$ならば$B^c in scr(B)$である．ここで，$B^c$は$B$の補集合である．
  3. $B_n in scr(B), n in NN$ならば$union.big_(n in NN) B_n in scr(B)$である．

  集合$Omega$と$Omega$上の$sigma$加法族$scr(B)$に対し，対$(Omega, scr(B))$を
  *可測空間*と呼ぶ．
  また，$scr(B)$の元を$Omega$の*可測集合*と呼ぶ．
]

#index(display: "確率測度")[かくりつそくど]
#index(display: "確率空間")[かくりつくうかん]
#index(display: "確率")[かくりつ]
#index(display: "標本空間")[ひょうほんくうかん]
#index(display: "標本点")[ひょうほんてん]
#index(display: "事象")[ししょう]
#definition(title: "確率空間")[
  可測集合$(Omega, scr(B))$が与えられたとき，写像$P colon scr(B) arrow.r.long RR$で以下の条件を満たすものを可測空間$(Omega, scr(B))$上の*確率測度*といい，対$(Omega, scr(B), mu)$を*確率空間*という．

  1. すべての$B in scr(B)$に対して$P(B) gt.eq 0$
  2. $B_n in Omega, n in NN$であって，すべての$i, j in NN$に対して$B_i inter B_j = emptyset$ならば
  $
    P(union.big_(n in NN) B_n) = sum_(n in NN) P(B_n).
  $
  3. $P(Omega) = 1.$

  確率空間$(Omega, scr(B), P)$について議論する文脈では，
  $Omega$を*標本空間*，その元を*標本点*，$scr(B)$の元，すなわち$Omega$の可測集合を*事象*という．
  さらに，各$B in scr(B)$に対する$P(B)$を$B$の*確率*という．
] <def:probability-space>

@def:probability-space は無限集合を標本空間とする確率空間も定義できるよう表記が抽象的になっているが，本質的には$Omega$を細分してそれぞれに対する割合を与えているに過ぎない．

さて， @def:probability-space にはランダム性にかかわる概念は一切登場しなかった．これは，事象の確率を表す写像$P$が$Omega$や$scr(B)$から自然に決まることを要請しないことによるものである．
現実世界とは無関係の確率空間の概念が現実世界における試行とどう対応するかを見てみよう．

#example[
  コインを1回投げるという試行を考える．
  事象として「表が出る」「裏が出る」の2通りがあるとしよう．
  $p$を0以上1以下の実数とする．
  $Omega = {0, 1}$とし，$scr(B) = frak(P)(Omega)$とする．ここで，$frak(P)(Omega)$は$Omega$のべき集合である．
  さらに，写像$P colon scr(B) arrow.r.long RR$を
  #set math.equation(numbering: none)
  $
    P(emptyset) & = 0, \
         P({0}) & = 1 - p, \
         P({1}) & = p, \
       P(Omega) & = 1
  $
  と定める．このとき，$(Omega, scr(B), P)$は確率空間である．

  現実世界における「コインを1回投げる」という試行は，
  この確率空間$(Omega, scr(B), P)$について考えることに対応させることができる．
  例えば，確率空間において$P({1}) = p$であることは現実世界における「コインを1回投げて表が出る確率は$p$である」という主張に対応させることができる．

  しかしこの「対応づけ」が適切であることを確認するのは，確率空間の性質から現実世界における試行についての知見を得ようとする当人の責務である．
  「対応させることができる」と書いて見せたが，証明できるのは数理モデルとしての確率空間の性質だけであってこの現実世界における試行と数理モデルとしての確率空間との対応が適切であることを「証明」したわけではないからである．
]

#example[
  対応づけの適切さを議論する必要性が明示的にわかる例として， @example-mathematical-probability に登場した「コインを2回投げる」という試行を考えよう．
  パターンの洗い出し方で2通りの考え方が登場したが，これは2種類の確率空間のどちらをこの試行と対応させようか，という議論に翻訳することができる：

  1. 以下で定義される確率空間$(Omega, scr(B), P)$：
  #set math.equation(numbering: none)
  $
        Omega & = {(0, 0), (0, 1), (1, 1)}, \
       scr(B) & = frak(P)(Omega), \
    P({0, 0}) & = P({0, 1}) = P({1, 0}) = P({1, 1}) = 1 / 4.
  $
  2. 以下で定義される確率空間$(Omega', scr(B)', P')$：
  $
     Omega' & = {0, 1, 2}, \
    scr(B)' & = frak(P)(Omega'), \
      P'(0) & = P'(1) = P'(2) = 1 / 3.
  $

  前者は2枚のコインを区別したうえでその裏表の組み合わせすべてを標本点としているが，後者は2枚のコインを区別せず表が出た回数のみを標本点としている．

  このとき，現実世界における「ちょうど表が1回出る事象の確率」は確率空間$(Omega, scr(B), P)$においては$P({0, 1} union {1,0}) = P({0, 1}) + P({1, 0}) = 1 / 2$となり確率空間$(Omega', scr(B)', P')$においては$P(1) = 1 / 3$となる．
  このうちどちらが「適切」であるかはこれだけではわからない．

  もし仮に，目的が「ちょうど表が1回出る事象の確率を計算すること」であったとしたら前者が適切かもしれない．
  しかし適切であることの完璧な根拠を与えることは不可能である．
  そもそも現実世界における確率というものにしっかりした定義はないということも述べている．
  せいぜい実験でもして「表が1回だけ出る相対頻度が$1 / 2$に近そうな気がするからたぶんこっちなんだろうなぁ」と思うのが限度である．そして，この限界に正面から立ち向かうのが統計学の典型的な応用先の1つである．
]

次に，条件付き確率を考えよう．

#index(display: "条件付き確率")[しょうけんつきかくりつ]
#definition(title: "条件付き確率")[
  確率空間$(Omega, scr(B), P)$において，$B in scr(B)$が$P(B) > 0$を満たすとする．このとき，$A in scr(B)$に対して
  $
    P(A | B) = P(A inter B) / P(B)
  $
  と定める．このとき，$P(A | B)$を$B$のもとでの$A$の*条件付き確率*という．
]

条件付き確率については，その定義が現実世界におけるどんな試行をイメージしたものなのかが少しわかりづらい．例を挙げよう．

#example[
  ある工場は1つの製品をX, Yの2つの設備を使って生産しており，全体の生産量に対する良品，不良品の割合がおおよそ @tab:condition-example で与えられるものとする．
  このとき，この工場で生産した製品をランダムに抽出する，という試行に対する確率空間を以下のように定義できる：

  #set math.equation(numbering: none)
  $
        Omega & = {{x, g}, {x, b}, {y, g}, {y, b}}, \
       scr(B) & = frak(P)(Omega), \
    P({x, g}) & = 0.76, \
    P({x, b}) & = 0.04, \
    P({y, g}) & = 0.17, \
    P({y, b}) & = 0.03
  $

  そして，$X = {x, g} union {x, b}, B = {x, b} union {y, b}$とおくと
  $
    P(X | B) = P(X inter B) / P(B) = P({x, b}) / (P({x, b}) + P({y, b})) = 0.04 / 0.07 = 0.571...
  $
  となる．
  P(X | B)は， @tab:condition-example における不良品列だけを見た場合の設備Xの割合である．
  対応する事象としては「不良品を1つ抜き出して確認したところ，設備Xで生産されたものであった」ということになる．
  条件付き確率の概念は「事象を一部分のみに着目した場合に対応する確率空間はどう定義されるか？」に対する解答を与えているものと考えることができる．

  しかし何度も述べるように，この値が「不良品を1つ抜き出して確認したときに設備Xで生産されたものである確率」と一致しているかどうかはよくわからない．
  そもそも現実世界における「確率」はしっかりした定義と呼べるものはないということもすでに述べている．
]

#figure(
  table(
    columns: 4,
    align: center,
    [], [良品], [不良品], [合計],
    [設備X], [0.76], [0.04], [0.8],
    [設備Y], [0.17], [0.03], [0.2],
    [合計], [0.93], [0.07], [1],
  ),
  caption: "ある工場における設備別良品率",
) <tab:condition-example>

さて，確率空間$(Omega, scr(B), P)$において，$A, B in scr(B)$が
$P(A) > 0$と$P(B) > 0$をともに満たすとする．このとき，
$P(A | B) P(B) = P(A inter B) = P(B | A) P(A)$であるから以下が成り立つ．
$
  P(A | B) = (P(B | A) P(A)) / P(B)
$ <eq:BayesTheorem>

この式は$P(A | B)$か$P(B | A)$のどちらか一方がわかれば$P(A), P(B)$を使ってもう一方も計算できるということを示している．
$P(A | B)$を考えるというのは，現実世界においては$B$を実験条件として必ず発生するよう固定する，ということに対応する．
そのようなことがさまざまな事情で困難な場合に代わりに$A$を固定して実験してもよい，ということになる．
上記のような利用方法は，条件付き確率の単純だが強力な応用先の1つである．

最後に確率変数を定義しよう．素朴には「確率的に変動する数」などといわれることがあるが，確率空間の言葉であいまいさ抜きに定義しよう．

#index(display: "確率変数")[かくりつへんすう]
#index(display: "（確率変数の）実現値")[しつげんち]
#index(display: "Borel集合族")[Borelしゅうごうぞく]
#definition(title: "確率変数")[
  実数全体の集合$RR$上の開集合全体から生成される$sigma$加法族を$RR$の*Borel集合族*という
  #footnote[
    登場する用語をほとんど定義していないのでなんのことだかわかりにくいが，とりあえずここではBorel集合族というのはここでは$RR$における区間，および区間同士の和集合や共通部分のとって得られる集合たちのことであると考えておけばよい．
  ]．
  $RR$におけるBorel集合族を$frak(B)(RR)$で表記する．
  $frak(B)(RR)$は$RR$上の$sigma$加法族である．

  確率空間$(Omega, scr(B), P)$において，写像$X colon Omega arrow.r.long RR$が確率空間$(Omega, scr(B), P)$上の*確率変数*であるとは，任意の$R in frak(B)(RR)$に対して
  $X^(-1)(R) in scr(B)$が成り立つことをいう．
  このとき，各$omega in Omega$に対する$X(omega) in RR$を，
  $omega$における$X$の*実現値*という．
]

「写像なのに変数と呼ぶの？」と思うかもしれない．
中学校あたりで「$y$は$x$の関数である」のように関数のことを数同士の対応というより数そのものが変化している変数であるという見方をすることがあるが，それと同じようなものであると考えればわかりやすい．

$Omega$からの写像を考える，という部分はともかくなぜBorel集合族が出てくるのか，なぜ$X^(-1)(R) in scr(B)$などという条件が出てくるのか，と考えるだろう．
前者はともかく後者については簡単に解答できる．
$X^(-1)(R) in scr(B)$ということは，この集合に対する確率$P(X^(-1)(R))$を考えることができる．
$R$は実数からなる集合なので，この確率は「$X$の実現値がこうなる確率はいくらか？」という問題に対する解答となっている．
このような問題に対していつでも解答を与えることができる，というのが確率変数の定義に課せられた制約である．

#index(display: "分布")[ふんぷ]
#index(display: "分布関数")[ふんぷかんすう]
#index(display: "確率密度関数")[かくりつみつどかんすう]
#index(display: "確率関数")[かくりつかんすう]
#definition[
  $X$を確率空間$(Omega, scr(B), P)$上の確率変数であるとする．
  このとき，写像$P^X colon frak(B)(RR) arrow.r.long RR$を以下で定める：
  $
    P^X (R) = P(X^(-1)(R))
  $
  このとき，$P^X$は可測空間$(RR, frak(B)(RR))$上の確率測度となる．この確率測度$P^X$を$X$の*分布*という．
  また，写像$F_X colon RR arrow.r.long RR$を以下のように定める：
  $
    F_X (x) = P^X ((-infinity, x])
  $
  $F_X$を$X$の*分布関数*という．
  $F_X$が$X$よりも先に与えられている文脈では，$X$は分布$F_X$に従うと表現することがある．
  また，写像$f_X colon RR arrow.r.long RR$を以下のように定める：
  $
    f_X (x) = P^X ({x})
  $
  この$f_X$を$X$の*確率密度関数*，あるいは単に*確率関数*という．
]

#index(display: "二項分布")[にこうぶんぷ]
#index(display: "パラメータ")[はらめーた]
#example[
  #set math.equation(numbering: none)
  $n$を正の整数，$p$を0以上1以下の実数とする．
  いま，確率空間$(Omega, scr(B), P)$を以下のように定める：
  $
         Omega & = {0, 1}^n = {0,1} times {0,1} times dots.h.c times {0,1}, \
        scr(B) & = frak(P)(Omega), \
    P({omega}) & = binom(n, k) p^(k) (1 - p)^(k).
  $
  ここで，$omega = (omega_1, omega_2, dots, omega_n) in Omega$とし，$k = sum omega_i$とした．
  さらに，$omega = (omega_1, omega_2, dots, omega_n) in Omega$に対して
  $
    X (omega) = sum omega_i
  $
  で確率空間$(Omega, scr(B), P)$上の確率変数$X colon Omega arrow.r.long RR$を定義する．$X$が従う分布を*二項分布*という．
  二項分布は，0, 1で表現できる二値的な結果を出力する試行を何度も繰り返した場合の結果に関する分布であるとみなすことができる．
  $n$は試行の実施回数，$p$は1回の試行で1が出る確率とみなすことができる．

  二項分布は正の整数$n$と0以上1以下の実数$p$の2つによって特徴づけられる．このような分布を特徴づける数のことを*パラメータ*と呼ぶ．
  正の整数$n$と0以上1以下の実数$p$で特徴づけられる二項分布を以下のように表す．
  $
    bin(n, p).
  $
]

#remark[
  ここでいう「パラメータ」は「母数」と呼ばれることもある．
  一方で，特に「母」という字は「母集団」や「母平均」のように統計学においては「現実世界における目的の集団」を指すことが多い．上記の「パラメータ」はもちろん数理モデル内の概念であり現実世界とは一切関係はない
  #footnote[
    数理モデル内のパラメータに現実世界での対応物が存在するのであれば，理解促進のためにそれが提示されることがある．しかしそれは「パラメータ」が現実世界における概念であることは意味しない．
  ]
  ．
]

#definition(title: "期待値")[
  確率空間$(Omega, scr(B), P)$上の確率変数$X$について，
  以下の式が有限確定の実数を表すのであれば，
  その値を$X$の*期待値*という：
  $
    E[X] = sum_(omega in Omega) X(omega) P({omega})
  $
]

#example[
  詳細は省くが，二項分布$bin(n, p)$のに従う確率変数$X$の期待値は
  $
    E[X] = n p
  $
  である．
] <ex:bin-expectation>

公理的確率論における確率は，まさしく割合の抽象化であった．期待値の計算式を見ると，確率変数の実現値をその割合で重みづけして足し合わせている．
このことからもわかるように，期待値はよく知られている平均値に確率の概念を導入したものと考えられる．

最後に，やや技術的ではあるが独立性について定義しておく．

#index(display: "（確率変数が）独立")[とくりつ]
#definition[
  確率空間$(Omega, scr(B), P)$上の確率変数$X_1, X_2, dots, X_n$が*独立である*とは，任意の$B_1, B_2, dots, B_n in frak(B)(RR)$に対して以下が成り立つことをいう：
  $
    P(inter.big_(i=1)^n X_i^(-1) (B_i)) = product_(i = 1)^n P(X^(-1)_i (B_i))
  $
]
